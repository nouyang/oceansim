{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c32b2f6-fba1-4759-a1ed-38626792e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import gym\n",
    "import random\n",
    "\n",
    "from gym import Env, spaces\n",
    "import time\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL \n",
    "\n",
    "class OceanScape(Env):\n",
    "    def __init__(self):\n",
    "        super(OceanScape, self).__init__()\n",
    "\n",
    "        # Define a 2-D observation space\n",
    "        self.observation_shape = (600, 800, 3)\n",
    "        self.canvas_size = self.observation_shape[:2]\n",
    "        self.observation_space = spaces.Box(low = np.zeros(self.observation_shape),\n",
    "                                            high = np.ones(self.observation_shape),\n",
    "                                            dtype = np.float16)\n",
    "\n",
    "        # Define an action space ranging from 0 to 4\n",
    "        #{0: \"Right\", 1: \"Left\", 2: \"Down\", 3: \"Up\", 4: \"Do Nothing\"}\n",
    "        self.action_space = spaces.Discrete(5,)\n",
    "\n",
    "        # Create a canvas to render the environment images upon\n",
    "        self.canvas = np.ones(self.observation_shape) * 1\n",
    "\n",
    "        # Define elements present inside the environment\n",
    "        self.elements = []\n",
    "\n",
    "        # Maximum battery can take at once\n",
    "        self.max_battery = 1000\n",
    "\n",
    "        # Permissible area of buoy to be\n",
    "        self.y_min = int(self.observation_shape[0] * 0.1)\n",
    "        self.x_min = 0\n",
    "        self.y_max = int (self.observation_shape[0] * 0.9)\n",
    "        self.x_max = self.observation_shape[1]\n",
    "\n",
    "        self.goal = [np.random.rand()* self.canvas_size[0],\n",
    "                    np.random.rand()* self.canvas_size[1]]\n",
    "                     # x and y\n",
    "        print('goal: ', self.goal)\n",
    "        self.goal_radius = 10\n",
    "\n",
    "\n",
    "# I need to store all the visited points to plot them\n",
    "# Agent will have full access to current environment and map\n",
    "# (in future -- may make reality more complicated than ideal observation)\n",
    "\n",
    "\n",
    "# reset to initial state: Fixed start and goal locations, Semi random wind\n",
    "# field\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the fuel consumed\n",
    "        self.batt_left = self.max_battery\n",
    "\n",
    "        # Reset the reward\n",
    "        self.ep_return = 0 \n",
    "\n",
    "\n",
    "        # Determine a place to intialise the chopper in\n",
    "        x = random.randrange(int(self.observation_shape[0] * 0.05), int(self.observation_shape[0] * 0.10))\n",
    "        y = random.randrange(int(self.observation_shape[1] * 0.15), int(self.observation_shape[1] * 0.20))\n",
    "\n",
    "        # Intialise the chopper\n",
    "        self.buoy = Buoy(\"buoy\", self.x_max, self.x_min, self.y_max, self.y_min)\n",
    "        self.buoy.set_position(x,y)\n",
    "\n",
    "\n",
    "        self.elements = [self.buoy]\n",
    "\n",
    "\n",
    "        # Reset the Canvas\n",
    "        self.canvas = np.ones(self.observation_shape) * 1\n",
    "\n",
    "        # Draw elements on the canvas\n",
    "        self.draw_elements_on_canvas() # TODO: why this no work?\n",
    "\n",
    "\n",
    "        # return the observation\n",
    "        return self.canvas \n",
    "\n",
    "# Step: movement is omni, but fuel budget is reduced based on direction\n",
    "    def inGoalRegion(self):\n",
    "        #print(f'position {self.buoy.get_position()}, goal {self.goal}')\n",
    "        #dist = np.linalg.norm(self.buoy.get_position() - self.goal) \n",
    "        b_x, b_y = self.buoy.get_position()\n",
    "        \n",
    "        dist = np.sqrt( (b_x - self.goal[0])**2 + (b_y - self.goal[1])**2)\n",
    "        if dist < self.goal_radius:\n",
    "            #print('distance', dist)\n",
    "            print(f'hurray! in goal region {self.goal},'\n",
    "                  ' posit {self.b_x}, {self.b_y}')\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        #print(action)\n",
    "        # Flag that marks the termination of an episode\n",
    "        done = False\n",
    "\n",
    "        # Assert that it is a valid action\n",
    "        assert self.action_space.contains(action), \"Invalid Action\"\n",
    "\n",
    "        # Decrease the fuel counter\n",
    "        self.batt_left -= 1\n",
    "\n",
    "        # Reward for executing a step.\n",
    "        reward = 1\n",
    "\n",
    "        # apply the action to the chopper\n",
    "        if action == 0:\n",
    "            self.buoy.move(0,5)\n",
    "        elif action == 1:\n",
    "            self.buoy.move(0,-5)\n",
    "        elif action == 2:\n",
    "            self.buoy.move(5,0)\n",
    "        elif action == 3:\n",
    "            self.buoy.move(-5,0)\n",
    "        elif action == 4:\n",
    "            self.buoy.move(0,0)\n",
    "\n",
    "\n",
    "        # Increment the episodic return\n",
    "        if self.inGoalRegion(): \n",
    "            # giant pot for reaching end goal as a function of batt left\n",
    "            self.ep_return += 0.1 * (self.max_battery - self.batt_left)\n",
    "            print(f'reached goal, final return {self.ep_return}')\n",
    "            done = True\n",
    "        # else:\n",
    "            #TODO: change this! Some heuristic I guess... Right now sparse\n",
    "            # Reward is zero on all transitions, except those into the goal state, on which it is +1. After reaching the goal state (G), the agent returns to the start state (S) to begin a new episode.\n",
    "        # If out of fuel, end the episode.\n",
    "        if self.batt_left == 0:\n",
    "            self.ep_return = -10\n",
    "            print(f'oops ran out of battery, final return {self.ep_return}')\n",
    "            done = True\n",
    "\n",
    "        # Draw elements on the canvas\n",
    "        self.draw_elements_on_canvas()\n",
    "\n",
    "        return self.canvas, reward, done, []\n",
    "\n",
    "# Render: renders wind field, current location, and visited locations, as\n",
    "# well as start and goal locations\n",
    "    def render(self, mode = \"human\"):\n",
    "        assert mode in [\"human\", \"rgb_array\"], \"Invalid mode, must be either \\\"human\\\" or \\\"rgb_array\\\"\"\n",
    "        if mode == \"human\":\n",
    "            cv2.imshow(\"Game\", self.canvas)\n",
    "            cv2.waitKey(10)\n",
    "\n",
    "        elif mode == \"rgb_array\":\n",
    "            return self.canvas\n",
    "# This is created on opencv2.  \n",
    "\n",
    "\n",
    "    def get_action_meanings(self):\n",
    "        return {0: \"Right\", 1: \"Left\", 2: \"Down\", 3: \"Up\", 4: \"Do Nothing\"}\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    def draw_elements_on_canvas(self):\n",
    "        # Init the canvas \n",
    "        self.canvas = np.ones(self.observation_shape) * 1\n",
    "\n",
    "        #def plot_path(self, path, cl='r', flag=False):\n",
    "            #path_x = [path[i][0] for i in range(len(path))]\n",
    "            #path_y = [path[i][1] for i in range(len(path))]\n",
    "\n",
    "        # Draw the heliopter on canvas\n",
    "        for elem in self.elements:\n",
    "            elem_shape = elem.icon.shape\n",
    "            x,y = elem.x, elem.y\n",
    "            self.canvas[y : y + elem_shape[1], x:x + elem_shape[0]] = elem.icon\n",
    "            \n",
    "            breadcrumbs = elem.get_history()\n",
    "\n",
    "            for crumb in breadcrumbs:\n",
    "                p_x, p_y = crumb\n",
    "                # Use less efficient method for now \n",
    "                self.canvas = cv2.circle(self.canvas, (p_x, p_y), radius=2,\n",
    "                                         color=(0, 0, 255), thickness=-1) \n",
    "\n",
    "        text = 'Batt Left: {} | Rewards: {}'.format(self.batt_left, self.ep_return)\n",
    "\n",
    "        # Put the info on canvas \n",
    "        self.canvas = cv2.putText(self.canvas, text, (10,20), font,  \n",
    "                   0.8, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "class Point(object):\n",
    "    def __init__(self, name, x_max, x_min, y_max, y_min):\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.y_min = y_min\n",
    "        self.y_max = y_max\n",
    "        self.name = name\n",
    "\n",
    "        self.history = []\n",
    "    \n",
    "    def set_position(self, x, y):\n",
    "        self.x = self.clamp(x, self.x_min, self.x_max - self.icon_w)\n",
    "        self.y = self.clamp(y, self.y_min, self.y_max - self.icon_h)\n",
    "    \n",
    "    def get_position(self):\n",
    "        return (self.x, self.y)\n",
    "    \n",
    "    def move(self, del_x, del_y):\n",
    "        self.x += del_x\n",
    "        self.y += del_y\n",
    "        \n",
    "        self.x = self.clamp(self.x, self.x_min, self.x_max - self.icon_w)\n",
    "        self.y = self.clamp(self.y, self.y_min, self.y_max - self.icon_h)\n",
    "\n",
    "        self.history.append((self.x, self.y))\n",
    "\n",
    "    def clamp(self, n, minn, maxn):\n",
    "        return max(min(maxn, n), minn)\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history \n",
    "\n",
    "\n",
    "class Buoy(Point):\n",
    "    def __init__(self, name, x_max, x_min, y_max, y_min):\n",
    "        super(Buoy, self).__init__(name, x_max, x_min, y_max, y_min)\n",
    "        self.icon = cv2.imread(\"argo_buoy.png\") / 255.0\n",
    "        self.icon_w = 64\n",
    "        self.icon_h = 64\n",
    "        self.icon = cv2.resize(self.icon, (self.icon_h, self.icon_w))\n",
    "\n",
    "\n",
    "\n",
    "# NOTES: \n",
    "    # You can use cv2.circle() function opencv module:\n",
    "    # image = cv.circle(image, centerOfCircle, radius, color, thickness)\n",
    "    # Keep radius as 0 for plotting a single point and thickness as a negative number for filled circle\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45ee9fdc-f169-43ba-9f6f-ff939a42cca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nrw/v3/lib/python3.8/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float16\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal:  [409.5177767606199, 615.3709473843388]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "env = OceanScape()\n",
    "obs = env.reset()\n",
    "\n",
    "while True:\n",
    "    # Take a random action\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "    # Render the game\n",
    "    env.render()\n",
    "\n",
    "    if done == True:\n",
    "        print('done')\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4680c9-2d32-4acd-8e08-3f0076171626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6beec991-f093-4960-8d72-e82da8f1f52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal:  [425.4419238745836, 603.744210580978]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f80b9821b50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = OceanScape()\n",
    "obs = env.reset()\n",
    "screen = env.render(mode = \"rgb_array\")\n",
    "plt.imshow(screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66eefe0d-c83c-4d95-9a30-cd6d9105865a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChopperScape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6524833539f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChopperScape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ChopperScape' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "env = ChopperScape()\n",
    "obs = env.reset()\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Take a random action\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    # Render the game\n",
    "    env.render()\n",
    "    \n",
    "    if done == True:\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8830210-a9fe-480a-b78f-3ee5d4b8babd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
